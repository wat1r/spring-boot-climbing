# 深入理解Kafka原理（一）
## 简介
Kafka是用scala语言编写，最初由Linkedin公司开发，后贡献给了Apache基金会并成为顶级开源项目。是一个分布式、支持分区的（partition）、多副本的（replication），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等。
Kafka是一个类JMS消息队列，结合了JMS中的两种模式，可以有多个消费者主动拉取数据。虽然它提供了类似于JMS的特性，但是在设计实现上完全不同，此外它并不是JMS规范的实现，在JMS中只有点对点模式才有消费者主动拉取数据。
特性
## 特性
- 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition，consumer group 对 partition 进行consume操作。
- 可扩展性：kafka集群支持热扩展
- 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- 容错性：允许集群中节点失败（若副本数量为n，则允许n-1个节点失败）
- 高并发：支持数千个客户端同时读写
- 顺序性：由生产者发送到一个特定的主题分区的消息将被以他们被发送的顺序来追加。也就是说，
如果一个消息M1和消息M2都来自同一个生产者，M1先发，那么M1将有一个低于M2的偏移，会更早在日志中出现。
消费者看到的记录排序就是记录被存储在日志中的顺序。
## 设计思想
### 动机
各种应用系统诸如商业、社交、搜索、浏览等像信息工厂一样不断的生产出各种信息，在大数据时代，我们面临如下几个挑战：
- 如何收集这些巨大的信息
- 如何分析它
- 如何及时做到如上两点
以上几个挑战形成了一个业务需求模型，即生产者生产（`produce`）各种信息，消费者消费（`consume`）（处理分析）这些信息，而在生产者与消费者之间，需要一个沟通两者的桥梁-消息系统。从一个微观层面来说，这种需求也可理解为不同的系统之间如何传递消息
1.Kafka 必须具有高吞吐量来支持高容量事件流，例如实时日志聚合；
2.Kafka 需要能够正常处理大量的数据积压，以便能够支持来自离线系统的周期性数据加载；
具有低延迟、分区、分布式、实时处理以及容错。
## 概念
#### Broker
kafka 集群由多个 kafka 实例组成，每个实例 (server) 称为 broker ，在集群中每个broker都有一个唯一brokerid，不得重复。 无论是 kafka 集群，还是 producer 和 consumer 都依赖于 zookeeper 来保证系统可用性，为集群保存一些 meta （元数据）信息。
#### Topics/Log
让我们首先深入了解下Kafka的核心概念:提供一串流式的记录— topic 。
Topic 就是数据主题，是数据记录发布的地方,可以用来区分业务系统。Kafka中的Topics总是多订阅者模式，一个topic可以拥有一个或者多个消费者来订阅它的数据。
对于每一个topic， Kafka集群都会维持一个分区日志，如下所示：
![image-20210320135717817](/Users/frankcooper/Library/Application Support/typora-user-images/image-20210320135717817.png)
每个分区都是有序且顺序不可变的记录集，并且不断地追加到结构化的commit log文件。分区中的每一个记录都会分配一个id号来表示顺序，我们称之为*offset*，*offset*用来唯一的标识分区中每一条记录。
Kafka 集群保留所有发布的记录—无论他们是否已被消费—并通过一个可配置的参数——保留期限来控制. 举个例子， 如果保留策略设置为2天，一条记录发布后两天内，可以随时被消费，两天过后这条记录会被抛弃并释放磁盘空间。Kafka的性能和数据大小无关，所以长时间存储数据没有什么问题.
![image-20210320140833189](/Users/frankcooper/Library/Application Support/typora-user-images/image-20210320140833189.png)
事实上，在每一个消费者中唯一保存的元数据是offset（偏移量）即消费在log中的位置.偏移量由消费者所控制:通常在读取记录后，消费者会以线性的方式增加偏移量，但是实际上，由于这个位置由消费者控制，所以消费者可以采用任何顺序来消费记录。例如，一个消费者可以重置到一个旧的偏移量，从而重新处理过去的数据；也可以跳过最近的记录，从"现在"开始消费。
这些细节说明Kafka 消费者是非常廉价的—消费者的增加和减少，对集群或者其他消费者没有多大的影响。比如，你可以使用命令行工具，对一些topic内容执行 tail操作，并不会影响已存在的消费者消费数据。
日志中的 partition（分区）有以下几个用途。第一，当日志大小超过了单台服务器的限制，允许日志进行扩展。每个单独的分区都必须受限于主机的文件限制，不过一个主题可能有多个分区，因此可以处理无限量的数据。第二，可以作为并行的单元集—关于这一点，更多细节如下

### Producer

生产者可以将数据发布到所选择的topic（主题）中。生产者负责将记录分配到topic的哪一个 partition（分区）中。可以使用循环的方式来简单地实现负载均衡，也可以根据某些语义分区函数(例如：记录中的key)来完成。
默认是defaultPartition Utils.abs(key.hashCode) % numPartitions

### Consumer



## Reference
https://www.cnblogs.com/sujing/p/10960832.html
https://blog.csdn.net/suifeng3051/article/details/48053965
https://segmentfault.com/a/1190000003922549
https://kafka.apachecn.org/
http://kafka.apache.org/documentation/#introduction
https://segmentfault.com/a/1190000015886371