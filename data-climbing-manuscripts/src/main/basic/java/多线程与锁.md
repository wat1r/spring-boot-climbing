

## 1.基础概念
### 1.0.什么是线程？线程和进程的区别

##### 进程：

进程来对应一个程序，每个进程对应一定的内存地址空间，并且只能使用它自己的内存空间，各个进程间互不干扰
这就是并发，能够让操作系统从宏观上看起来同一个时间段有多个任务在执行。换句话说，进程让操作系统的并发成为了可能。

##### 线程：

让一个线程去执行一个子任务，这样一个进程就包括了多个线程，每个线程负责一个独立的子任务，这样在用户点击按钮的时候，就可以暂停获取图像数据的线程，让UI线程响应用户的操作，响应完之后再切换回来，让获取图像的线程得到CPU资源
 线程和进程有什么区别？
一个进程是一个独立(self contained)的运行环境，它可以被看作一个程序或者一个应用。而线程是在进程中执行的一个任务。线程是进程的子集，一个进程可以有很多线程，每条线程并行执行不同的任务。不同的进程使用不同的内存空间，而所有的线程共享一片相同的内存空间。别把它和栈内存搞混，每个线程都拥有单独的栈内存用来存储本地数据。

### 1.1.进程间如何通信

##### 1.管道（pipe）及有名管道（named pipe）： 

管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。 

##### 2.信号（signal）： 

信号是在软件层次上对中断机制的一种模拟，它是比较复杂的通信方式，用于通知进程有某事件发生，一个进程收到一个信号与处理器收到一个中断请求效果上可以说是一致的。 

##### 3.消息队列（message queue）： 

消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息。 

##### 4.共享内存（shared memory）： 

可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。 

##### 5.信号量（semaphore）： 

主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段。 

##### 6.套接字（socket）； 

这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。

### 1.2.如何理解线程安全

## 2.技术点

### 2.1.synchronized与Lock的区别

类别 synchronized Lock
存在层次 Java的关键字，在jvm层面上 是一个类
锁的释放 1、以获取锁的线程执行完同步代码，释放锁 2、线程执行发生异常，jvm会让线程释放锁 在finally中必须释放锁，不然容易造成线程死锁
锁的获取 假设A线程获得锁，B线程等待。如果A线程阻塞，B线程会一直等待 分情况而定，Lock有多个锁获取的方式，具体下面会说道，大致就是可以尝试获得锁，线程可以不用一直等待
锁状态 无法判断 可以判断
锁类型 可重入 不可中断 非公平 可重入 可判断 可公平（两者皆可）
性能 少量同步 大量同步

#### 2.1.1.sychronized与volatile关键字区别

![在这里插入图片描述](https://img-blog.csdnimg.cn/4201245760dd4aa797067573b618afa4.png)

##### sychronized与volatile关键字区别：

1、volatile关键字解决的是变量在多个线程之间的可见性；而sychronized关键字解决的是多个线程之间访问共享资源的同步性。
2、volatile只能用于修饰变量，而synchronized可以修饰方法以及代码块。（volatile是线程同步的轻量级实现，所以volatile性能比synchronized要好，并且随着JDK新版本的发布，synchronized关键字在执行上得到很大的提升，在开发中使用synchronized关键字的比率还是比较大。）
3、多线程访问volatile不会发生阻塞，而synchronized会发生阻塞。
4、volatile能保证变量在多个线程之间的可见性，但不能保证原子性；而synchronized可以保证原子性，也可以间接保证可见性，因为它会将私有内存和 公有内存中的数据做同步。
线程安全包含原子性和可见性两个方面。对于用volatile修饰的变量，JVM只是保证从主存加载到线程工作内存的值是最新的。一句话说明volatile的作用：实现变量在多个线程之间的可见性

### 2.2.ReentrantLock和Semaphore

独占式的同步组件实现tryAcquire和tryRelease，非独占式的实现tryAcquireShared和tryReleaseShared

### 2.3.锁机制

#### 2.3.1.[Java 对象锁和类锁全面解析](https://blog.csdn.net/u013142781/article/details/51697672)

#### 2.3.2.乐观锁和悲观锁

```java
public class AtomicInteger extends Number implements java.io.Serializable {
    //存储整数值，volatile保证可视性
    private volatile int value;
    //Unsafe用于实现对底层资源的访问
    private static final Unsafe unsafe = Unsafe.getUnsafe();
//valueOffset是value在内存中的偏移量
private static final long valueOffset;
//通过Unsafe获得valueOffset
static {
    try {
        valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField("value"));
    } catch (Exception ex) { throw new Error(ex); }
}
 
public final boolean compareAndSet(int expect, int update) {
    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
}
 
public final int getAndIncrement() {
    for (;;) {
        int current = get();
        int next = current + 1;
        if (compareAndSet(current, next))
            return current;
    }
}
```
}

源码分析说明如下：
getAndIncrement()实现的自增操作是自旋CAS操作：在循环中进行compareAndSet，如果执行成功则退出，否则一直执行。
其中compareAndSet是CAS操作的核心，它是利用Unsafe对象实现的。
Unsafe又是何许人也呢？Unsafe是用来帮助Java访问操作系统底层资源的类（如可以分配内存、释放内存），通过Unsafe，Java具有了底层操作能力，可以提升运行效率；强大的底层资源操作能力也带来了安全隐患(类的名字Unsafe也在提醒我们这一点)，因此正常情况下用户无法使用。AtomicInteger在这里使用了Unsafe提供的CAS功能。
valueOffset可以理解为value在内存中的偏移量，对应了CAS三个操作数(V/A/B)中的V；偏移量的获得也是通过Unsafe实现的。
value域的volatile修饰符：Java并发编程要保证线程安全，需要保证原子性、可视性和有序性；CAS操作可以保证原子性，而volatile可以保证可视性和一定程度的有序性；在AtomicInteger中，volatile和CAS一起保证了线程安全性。关于volatile作用原理的说明涉及到Java内存模型(JMM)，这里不详细展开。

##### ABA问题

##### 假设有两个线程——线程1和线程2，两个线程按照顺序进行以下操作：

线程1读取内存中数据为A；
线程2将该数据修改为B；
线程2将该数据修改为A；
线程1对数据进行CAS操作

Java中的AtomicStampedReference类便是使用版本号来解决ABA问题的。

#### 2.3.3.一句话明白各种锁

获取不到锁就马上进入阻塞状态的锁，我们称之为重量级锁。
然而重量级锁就是这么坑，它就是不肯等待一下，一拿不到就是要马上进入阻塞状态。为了解决这个问题，我们引入了另外一种愿意等待一段时间的锁 --- 自旋锁。
能够根据线程最近获得锁的状态来调整循环次数的自旋锁，我们称之为自适应自旋锁
轻量级锁适合用在那种，很少出现多个线程竞争一个锁的情况，也就是说，适合那种多个线程总是错开时间来获取锁的情况。
偏向锁进入一个方法的时候是这样处理的：如果这个方法没有人进来过，那么一个线程首次进入这个方法的时候，会采用CAS机制，把这个方法标记为有人在执行了，和轻量级锁加锁有点类似，并且也会把该线程的 ID 也记录进去，相当于记录了哪个线程在执行。

### 2.4.ThreadLocal

1. ##### 多进程之间如何通信？

  因为不同的进程会在内存中被分配不同的资源。所以多进程之间通信是一个问题，python的multiprocessing模块一共了一系列的交换方式，Queue, Pipe, Manager。
2. ##### 多线程之间如何通信？

  这就不是一个问题，因为线程间是共享所在进程变量的。所以通信不是问题，让它们同步才是问题，同步暂且不表。
3. ##### 不同进程间线程如何通信？

  这也不是个问题，因为这就是两个进程之间的通信。
4. ##### 一个线程内部如何通信？

  可能乍一看，觉得这也能是个问题？但，这才是真正的问题。

[ThreadLocal是用来做什么的？](https://blog.csdn.net/qq_21294095/article/details/85209523)


Java 并发编程：深入剖析 ThreadLocal

[什么是ThreadLocal](https://blog.csdn.net/moakun/article/details/79911989)


这个类有以下方法：

get()：返回当前线程拷贝的局部线程变量的值。
initialValue()：返回当前线程赋予局部线程变量的初始值。
remove()：移除当前线程赋予局部线程变量的值。
set(T value)：为当前线程拷贝的局部线程变量设置一个特定的值。

首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。

初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。

然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。

深入分析 ThreadLocal 内存泄漏问题



## 3.多线程并发

线程池核心参数介绍

#### 一、核心参数

corePoolSize（核心线程数）
（1）核心线程会一直存在，即使没有任务执行；
（2）当线程数小于核心线程数的时候，即使有空闲线程，也会一直创建线程直到达到核心线程数；
（3）设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭。
queueCapacity（任务队列容量）
也叫阻塞队列，当核心线程都在运行，此时再有任务进来，会进入任务队列，排队等待线程执行。
maxPoolSize（最大线程数）
（1）线程池里允许存在的最大线程数量；
（2）当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务；
（3）线程池里允许存在的最大线程数量。当任务队列已满，且线程数量大于等于核心线程数时，会创建新的线程执行任务。
keepAliveTime（线程空闲时间）
（1）当线程空闲时间达到keepAliveTime时，线程会退出（关闭），直到线程数等于核心线程数；
（2）如果设置了allowCoreThreadTimeout=true，则线程会退出直到线程数等于零。
allowCoreThreadTimeout（允许核心线程超时）
rejectedExecutionHandler（任务拒绝处理器）
（1）当线程数量达到最大线程数，且任务队列已满时，会拒绝任务；
（2）调用线程池shutdown()方法后，会等待执行完线程池的任务之后，再shutdown()。如果在调用了shutdown()方法和线程池真正shutdown()之间提交任务，会拒绝新任务。

#### 二、线程池参数默认值

corePoolSize = 1
queueCapacity = Integer.MAX_VALUE
maxPoolSize = Integer.MAX_VALUE
keepAliveTime = 60秒
allowCoreThreadTimeout = false
rejectedExecutionHandler = AbortPolicy()

#### 三、ThreadPoolExecutor（线程池）执行顺序

当线程数小于核心线程数时，创建线程。
当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。
当线程数大于等于核心线程数，且任务队列已满
若线程数小于最大线程数，创建线程
若线程数等于最大线程数，抛出异常，拒绝任务

#### 线程池拒绝策略分别使用在什么场景?

AbortPolicy中止策略：丢弃任务并抛出RejectedExecutionException异常。使用场景：这个就没有特殊的场景了，但是有一点要正确处理抛出的异常。当自己自定 义线程池实例时，使用这个策略一定要处理好触发策略时抛的异常，因为他会打断当前 的执行流程。

DiscardPolicy丢弃策略：ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出 异常。如果线程队列已满，则后续提交的任务都会被丢弃，且是静默丢弃。使用场景：如果你提交的任务无关紧要，你就可以使用它 。

DiscardOldestPolicy弃老策略：丢弃队列最前面的任务，然后重新提交被拒绝的任务。使用场景：这个策略还是会丢弃任务，丢弃时也是毫无声息，但是特点是丢弃的是老的 未执行的任务，而且是待执行优先级较高的任务。基于这个特性，能想到的场景就是， 发布消息和修改消息，当消息发布出去后，还未执行，此时更新的消息又来了，这个时 候未执行的消息的版本比现在提交的消息版本要低就可以被丢弃了。

CallerRunsPolicy调用者运行策略：由调用线程处理该任务。使用场景：一般在不允许失败的、对性能要求不高、并发量较小的场景下使用。

### 3.2.[线程池参数设置技巧](https://blog.csdn.net/strawqqhat/article/details/88749714)

一个核心池为2，等待队列3，最大线程数10的线程池，已有两个线程运行任务，第三个任务进来时如何处理
判断等待队列中是否有地方存放该任务，如果有就将任务保存在等待队列中等待执行，没有就去判断最大可容纳的线程数，如果没有超出这个数量就去开创非核心线程执行任务，否则调用handler实现拒绝策略。

## 4.并发

### 4.1.线程与进程

以操作系统的角度述说线程与进程
进程和线程的区别?

进程是资源分配的最小单位，线程是程序执行的最小单位。

进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。

线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。

但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

### 4.2. ThreadLocal 是什么，应用场景是什么，原理是怎样的

通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程 都有自己的专属本地变量该如何解决呢？ JDK 中提供的ThreadLocal 类正是为了解决这样的问题。 ThreadLocal 类主要解决的就是让每个线程绑定自己的值，可以将 ThreadLocal 类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。

如果你创建了一个 ThreadLocal 变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是 ThreadLocal 变量名的由来。他们可以使用 get()和 set() 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。 ThreadLocal 最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在ThreadLocal上， ThreadLocal 可以理解为只是ThreadLocalMap 的封装，传递了变量ThreadLocalMap 值。我们可以把ThrealLocal理解为ThreadLocal 类实现的定制化的 HashMap 。类中可以通过Thread.currentThread() 获取到当前线程对象后，直接通过getMap(Thread t) 可以访问到该线程的ThreadLocalMap 对象。每个 Thread 中都具备一个 ThreadLocalMap ，而 ThreadLocalMap 可以存储以ThreadLocal 为 key ，Object对象为 value 的键值对。


ThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {}   
比如我们在同一个线程中声明了两个 ThreadLocal 对象的话，会使用 Thread 内部都是使用仅有那个ThreadLocalMap 存放数据的， ThreadLocalMap 的 key 就是 ThreadLocal 对象，value 就是ThreadLocal 对象调用set 方法设置的值。

#### 4.2.1.ThreadLocal类为什么要加上private static修饰？

首先，private修饰与ThreadLocal本身没有关系，private更多是在安全方面进行考虑。static 修饰这个变量，这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此 类实例共享此静态变量，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此 类的对象(只要是这个线程内定义的)都可以操控这个变量。（设置为static可以避免每个线程从任务队列中获取task后重复创建ThreadLocal所关联的对象）可以解决内存泄露问题（看下一问）。

#### 4.2.2ThreadLocal有什么缺陷？如果线程池的线程使用ThreadLocal会有什么问题？

ThreadLocalMap如何解决冲突？

采用线性探测的方式 。


```java
public class Thread implements Runnable { 
	......
	ThreadLocal.ThreadLocalMap threadLocals = null;
	ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; 
    ......
}
```

ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来， ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set() 、 get() 、 remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal 方法后 最好手动调用remove() 方法。


```java
static class Entry extends WeakReference<ThreadLocal<?>> {
/** The value associated with this ThreadLocal. */
	Object value;
	Entry(ThreadLocal<?> k, Object v) {
		super(k);
		value = v; 
    }
}
```

在ThreadLocalMap中，也是用Entry来保存K-V结构数据的。但是Entry中key只能是ThreadLocal对象，这点被Entry的构造方法已经限定死了。Entry继承自WeakReference（ 弱引用，生命周期只能存活到下次GC前 ），但只有Key是弱引用类型的， Value并非弱引用。由于ThreadLocalMap的key是弱引用，而Value是强引用。这就导致了 一个问题，ThreadLocal在没有外部对象强引用时，发生GC时弱引用Key会被回收，而Value不会回收。当线程没有结束，但是ThreadLocal已经被回收，则可能导致线程中存在ThreadLocalMap<null, Object>的键值对，造成内存泄露。（ ThreadLocal被回收，ThreadLocal关联的线程共享变量还存在 ）。

为了防止此类情况的出现，我们有两种手段：

1、使用完线程共享变量后，显示调用ThreadLocalMap.remove()方法清除线程共享变量；

既然Key是弱引用，那么我们要做的事，就是在调用ThreadLocal的get()、set()方法时完成后再调用remove方法，将Entry节点和Map的引用关系移除，这样整个Entry对象在GC Roots 分析后就变成不可达了，下次GC的时候就可以被回收。

2、JDK建议ThreadLocal定义为private static，这样ThreadLocal的弱引用问题则不存在了。

### 4.7.锁

##### [最全Java锁详解：独享锁/共享锁+公平锁/非公平锁+乐观锁/悲观锁](https://blog.csdn.net/u013030086/article/details/85001354)

#### 4.7.1.乐观锁与悲观锁

悲观锁(Pessimistic Lock), 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。
乐观锁(Optimistic Lock), 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。
两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。

#### 4.7.2.公平锁 VS 非公平锁

公平锁
就是很公平，在并发环境中，每个线程在获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程是等待队列的第一个，就占有锁，否则就会加入到等待队列中，以后会按照FIFO的规则从队列中取到自己。
公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。
非公平锁
上来就直接尝试占有锁，如果尝试失败，就再采用类似公平锁那种方式。
　　 非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。

3.典型应用
java jdk并发包中的ReentrantLock可以指定构造函数的boolean类型来创建公平锁和非公平锁（默认）,比如：公平锁可以使用new ReentrantLock(true)实现。

#### 4.7.3.共享锁VS独占锁

##### 1.独享锁

是指该锁一次只能被一个线程所持有。

##### 2.共享锁

是指该锁可被多个线程所持有。

##### 3.比较

对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。
　　 读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。
　　 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。

##### 4.AQS

抽象队列同步器（AbstractQueuedSynchronizer，简称AQS）是用来构建锁或者其他同步组件的基础框架，它使用一个整型的volatile变量（命名为state）来维护同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。
　　 ![在这里插入图片描述](https://img-blog.csdnimg.cn/de62f7aec94744d3b7e7e41d655af407.png)

　　 concurrent包的实现结构如上图所示，AQS、非阻塞数据结构和原子变量类等基础类都是基于volatile变量的读/写和CAS实现，而像Lock、同步器、阻塞队列、Executor和并发容器等高层类又是基于基础类实现。

#### 4.7.4.分段锁

分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。
　　 我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。
　　 当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。
　　 但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。
　　 分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。

#### 4.7.5.Java线程锁总结

##### 1.synchronized：

在资源竞争不是很激烈的情况下，偶尔会有同步的情形下，synchronized是很合适的。原因在于，编译程序通常会尽可能的进行优化synchronize，另外可读性非常好。

##### 2.ReentrantLock:

在资源竞争不激烈的情形下，性能稍微比synchronized差点点。但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍，而ReentrantLock确还能维持常态。高并发量情况下使用ReentrantLock。

##### 3.Atomic:

和上面的类似，不激烈情况下，性能比synchronized略逊，而激烈的时候，也能维持常态。激烈的时候，Atomic的性能会优于ReentrantLock一倍左右。但是其有一个缺点，就是只能同步一个值，一段代码中只能出现一个Atomic的变量，多于一个同步无效。因为他不能在多个Atomic之间同步。所以，我们写同步的时候，优先考虑synchronized，如果有特殊需要，再进一步优化。ReentrantLock和Atomic如果用的不好，不仅不能提高性能，还可能带来灾难。
以上就是Java线程锁的详解，除了从编程的角度应对高并发，更多还需要从架构设计的层面来应对高并发场景，例如：Redis缓存、CDN、异步消息等。

#### 4.7.6.如何避免死锁

死锁预防

死锁避免

死锁检测

死锁解除

死锁预防： 破坏导致死锁必要条件中的任意一个就可以预防死锁。例如：

（1） 破坏保持和等待条件： 一次性申请所有资源，之后不再申请资源，如果不满足资源条件则得不到资源分配。

（2） 破坏不可剥夺条件： 当一个进程获得某个不可剥夺的资源时，提出新的资源申请，若不满足，则释放所有资源。

（3） 破坏循环等待条件： 按某一顺序申请资源，释放资源则反序释放。

死锁避免： 进程在每次申请资源时判断这些操作是否安全。

死锁检测： 判断系统是否属于死锁的状态，如果是，则执行死锁解除策略。

死锁解除： 将某进程所占资源进行强制回收，然后分配给其他进程。（与死锁检测结合使用的）

### 4.8.并发工具

#### 4.8.1.CountDownLatch

解释：一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。个人理解是CountDownLatch让可以让一组线程同时执行，然后在这组线程全部执行完前，可以让另一个线程等待。
就好像跑步比赛，10个选手依次就位，哨声响才同时出发；所有选手都通过终点，才能公布成绩。那么CountDownLatch就可以控制10个选手同时出发，和公布成绩的时间。


①某一线程在开始运行前等待n个线程执行完毕。将 CountDownLatch 的计数器初始化为n ：new CountDownLatch(n) ，每当一个任务线程执行完毕，就将计数器减1 countdownlatch.countDown()，当计数器的值变为0时，在CountDownLatch上 await()的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。
②实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 ：new CountDownLatch(1) ，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为0，多个线程同时被唤醒。
③死锁检测：一个非常方便的使用场景是，你可以使用n个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。
 CountDownLatch 的不足
CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。

##### CountDownLatch连击

 CountDownLatch相常见面试题：
解释一下CountDownLatch概念？

##### CountDownLatch 和CyclicBarrier的不同之处？

1.CountDownLatch是计数器，只能使用一次，而CyclicBarrier的计数器提供reset功能，可以多次使用。但是我不那么认为它们之间的区别仅仅就是这么简单的一点
2.对于CountDownLatch来说，重点是“一个线程（多个线程）等待”，而其他的N个线程在完成“某件事情”之后，可以终止，也可以等待。而对于CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。

![在这里插入图片描述](https://img-blog.csdnimg.cn/8a25d590a53447afaafc15a55ff3287e.png)

##### CyclicBarrier与CountDownLacth的区别：

1）CountDownLacth用于一个线程与一组线程之间的相互等待。常用的就是一个主线程与一组分治线程之间的等待：主线程发号令，一组线程同时执行；一组线程依次执行完，再唤醒主线程继续执行；
CyclicBarrier用于一组线程执行时，每个线程执行有多个节点，每个节点的处理需要相互等待。如：对5个文件进行处理，按行将各个文件数字挑出来合并成一行，排序，并输出到另一个文件，那每次处理都需要等待5个线程读入下一行。

CountDownLacth的处理机制是：初始化一个值N（相当于一组线程有N个），每个线程调用一次countDown()，那么cdLatch减1，等所有线程都调用过countDown()，那么cdLatch值达到0，那么线程从await()处接着玩下执行。
CyclicBarrier的处理机制是：初始化一个值N（相当于一组线程有N个），每个线程调用一次await()，那么barrier加1，等所有线程都调用过await()，那么barrier值达到初始值N，所有线程接着往下执行，并将barrier值重置为0，再次循环下一个屏障；
3）由2）可以知道，CountDownLatch只可以使用一次，而CyclicBarrier是可以循环使用的。


给出一些CountDownLatch使用的例子？
CountDownLatch 类中主要的方法？

## 4.9.杂项

### 4.9.1.volatile

https://blog.csdn.net/u011519624/article/details/63686701

##### [关于指令重排内存屏障和总线风暴](https://blog.csdn.net/li12127878/article/details/101001128)

总线风暴
由于volatile的mesi缓存一致性协议需要不断的从主内存嗅探和cas不断循环无效交互导致总线带宽达到峰值
解决办法：部分volatile和cas使用synchronize

### 4.9.2.happens-before原则

### 4.9.3 AtomicInteger 

2.AtomicInteger 线程安全原理简单分析
AtomicInteger 类的部分源码：

![在这里插入图片描述](https://img-blog.csdnimg.cn/c8b0a4dc29ea4ec6b83a17beb81a80a8.png)

AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。
CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。

### 4.9.4.AQS(AbstractQueuedSynchronizer)

##### 1.AQS原理

AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。

![在这里插入图片描述](https://img-blog.csdnimg.cn/c8846645d8c44d728ccd2fbd2c3284dc.png)

##### 2 AQS 对资源的共享方式

AQS定义两种资源共享方式
Exclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁：
公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的
Share（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。
ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。
不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在上层已经帮我们实现好了。

##### 3 AQS底层使用了模板方法模式

同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：
使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）
将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。
这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用，下面简单的给大家介绍一下模板方法模式，模板方法模式是一个很容易理解的设计模式之一。

追加：（AQS和CAS原理）
抽象队列同步器AQS（AbstractQueuedSychronizer），如果说java.util.concurrent的基础是CAS的话，那么AQS就是整个Java并发包的核心了，ReentrantLock、CountDownLatch、Semaphore等都用到了它。AQS实际上以双向队列的形式连接所有的Entry，比方说ReentrantLock，所有等待的线程都被放在一个Entry中并连成双向队列，前面一个线程使用ReentrantLock好了，则双向队列实际上的第一个Entry开始运行。AQS定义了对双向队列所有的操作，而只开放了tryLock和tryRelease方法给开发者使用，开发者可以根据自己的实现重写tryLock和tryRelease方法，以实现自己的并发功能。
比较并替换CAS(Compare and Swap)，假设有三个操作数：内存值V、旧的预期值A、要修改的值B，当且仅当预期值A和内存值V相同时，才会将内存值修改为B并返回true，否则什么都不做并返回false，整个比较并替换的操作是一个原子操作。CAS一定要volatile变量配合，这样才能保证每次拿到的变量是主内存中最新的相应值，否则旧的预期值A对某条线程来说，永远是一个不会变的值A，只要某次CAS操作失败，下面永远都不可能成功。
CAS虽然比较高效的解决了原子操作问题，但仍存在三大问题。
循环时间长开销很大。
只能保证一个共享变量的原子操作。
ABA问题。

##### [CAS了解及CAS容易发生的问题](https://blog.csdn.net/summerZBH123/article/details/80642467)



### 4.9.5.Semaphore 

http://www.importnew.com/20886.html
Semaphore 有两种模式，公平模式和非公平模式。

- 公平模式： 调用acquire的顺序就是获取许可证的顺序，遵循FIFO；

- 非公平模式： 抢占式的。

![在这里插入图片描述](https://img-blog.csdnimg.cn/eb872960943c471db31f491bbe206f20.png)

JAVA REENTRANTLOCK、SEMAPHORE 的实现与 AQS 框架
http://www.importnew.com/26319.html



##### [java.util.concurrent包下的几个常用类](https://blog.csdn.net/lh87522/article/details/45973373)

![在这里插入图片描述](https://img-blog.csdnimg.cn/647513bd94494057a34fea34880ecc1d.png)

CompletionService与Callable<V>+Future的对比：
在上面的Callable中说过，Callable+Future能实现任务的分治，但是有个问题就是：不知道call()什么时候完成，需要人为控制等待。
而jdk通过CompetionService已经将此麻烦简化，通过CompletionService将异步任务完成的与未完成的区分开来（正如api的描述），我们只用去取即可。
CompletionService有什么好处呢？
如上所说：

- 1）将已完成的任务和未完成的任务分开了，无需开发者操心；
- 2）隐藏了Future类，简化了代码的使用

### 4.9.6.synchronize的底层原理

synchronized (this)原理：涉及两条指令：monitorenter，monitorexit；再说同步方法，从同步方法反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来实现，相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。
JVM就是根据该标示符来实现方法的同步的：当方法被调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。
这个问题会接着追问：java对象头信息，偏向锁，轻量锁，重量级锁及其他们相互间转化。

### 4.9.7.transient

transient 关键字可以使一些属性不会被序列化。
ArrayList 中存储数据的数组 elementData 是用 transient 修饰的，因为这个数组是动态扩展的，并不是所有的空间都被使用，因此就不需要所有的内容都被序列化。通过重写序列化和反序列化方法，使得可以只序列化数组中有内容的那部分数据。

```java
private transient Object[] elementData;
```

### 4.9.8.线程与进程

进程是资源分配的基本单位，线程是调度的基本单位。进程包含线程，线程共用进程的资源。
进程：进程是指某个应用在处理机上的一次执行过程，是一个动态的概念，是一个活动的实体。 
线程：线程是进程的一部分，一个进程包含多个线程在运行。
一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。另外，线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点儿在运行中必不可少的资源，但它可与同属一个进程的其它线程共享进程所拥有的全部资源。
区别：

- (1)地址空间:进程内的一个执行单元;进程至少有一个线程;它们共享进程的地址空间;而进程有自己独立的地址空间; 
- (2)资源拥有:进程是资源分配和拥有的单位,同一个进程内的线程共享进程的资源 
- (3)线程是处理器调度的基本单位,但进程不是. 
- (4)二者均可并发执行.

### 4.9.9.线程间的通信

- （1）管道（Pipe）：管道可用于具有亲缘关系进程间的通信，允许一个进程和另一个与它有共同祖先的进程之间进行通信。 
- （2）命名管道（named pipe）：命名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。命名管道在文件系统中有对应的文件名。命名管道通过命令mkfifo或系统调用mkfifo来 创建。 
- （3）信号（Signal）：信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上，该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，用sigaction函数重新实现了signal函数）。 
- 　 （4）消息（Message）队列：消息队列是消息的链接表，包括Posix消息队列system V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺 
- 　　（5）共享内存：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。 
- 　　（6）内存映射（mapped memory）：内存映射允许任何多个进程间通信，每一个使用该机制的进程通过把一个共享的文件映射到自己的进程地址空间来实现它。 
- 　　（7）信号量（semaphore）：主要作为进程间以及同一进程不同线程之间的同步手段。 
- 　　（8）套接口（Socket）：更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由Unix系统的BSD分支开发出来的，但现在一般可以移植到其它类Unix系统上：Linux和System V的变种都支持套接字。